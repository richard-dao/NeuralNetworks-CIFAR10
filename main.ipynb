{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHQlcZT2i0ys"
      },
      "source": [
        "# Comparative Study of Neural Network and CNNs using the CIFAR-10 Dataset in Keras.\n",
        "\n",
        "\n",
        "### Part 1: Neural Network\n",
        "\n",
        "- Step 1: Design, compile, train, and evaluate a simple neural network\n",
        "\n",
        "- Step 2: Experiment with different activation functions and evaluate their influence on model performance\n",
        "\n",
        "- Step 3: Adjust and experiment with the number of parameters\n",
        "\n",
        "- Step 4: Experiment with the depth and width of neural networks\n",
        "\n",
        "- Step 5: Build an optimized neural network based on observations from previous tasks and analyze the performance.\n",
        "\n",
        "### Part 2: Convolutional neural network\n",
        "\n",
        "Use CNN to replace the vanilla neural network from Part 1 and report findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ftPSeJzHhenl"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fez0_R56R1bn"
      },
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYESQC1EjIyW",
        "outputId": "1d86f9ca-a46e-428c-d699-fccbbd4f7d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Load CIFAR Dataset from Keras\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to binary class matrices\n",
        "num_classes = 10\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Split the full training dataset into validation dataset in 80-20 ratio\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "x_train.shape, x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "wvTS7alnjRGI",
        "outputId": "070438bc-5029-405d-ebf8-5bb174a21f47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting function\n",
        "def plot_images(X, y, number_of_images=10):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(number_of_images):\n",
        "        plt.subplot(1, number_of_images, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_images(x_train_full, y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX14lObF4pgt"
      },
      "source": [
        "## Part 1: Neural Network\n",
        "### Step 1: Build a simple neural network\n",
        "First, build a simple neural network for the CIFAR-10 dataset. We will:\n",
        "\n",
        "Load the CIFAR-10 dataset from Keras. Normalize the data and transform the labels to a categorical format.\n",
        "\n",
        "Define a simple neural network using three hidden layers using 'relu' activation and a softmax output layer for the 10 classes of the CIFAR-10 dataset.\n",
        "\n",
        "Compile the model using 'categorical_crossentropy' for the loss function and 'adam' as the optimizer. The metrics will be 'accuracy'.\n",
        "\n",
        "Train the model using a validation split of 0.2. Train for 10 epochs.\n",
        "Evaluate the model on the test set and report its accuracy.\n",
        "\n",
        "### Step 2: Change the activation\n",
        "Next, we will experiment with different activation functions. Repeat the Step 1 process three times-- once with 'relu' replaced with 'sigmoid', once with 'tanh', and finally with 'gelu'. For each, we will evaluate the model's performance and document any changes.\n",
        "\n",
        "### Step 3: Change the number of parameters\n",
        "Now, we will significantly **increase** and **decrease** the number of parameters in the neural network (by an order of magnitude) and compare results.\n",
        "\n",
        "### Step 4: Change the depth and width\n",
        "Now, we will alter the structure of the neural network, specifically its depth and width, and compare results while trying to keep the number of parameters fixed.\n",
        "\n",
        "***Increasing the depth***: We will add more layers to the network to make the model deeper by adding more layers of neurons.\n",
        "\n",
        "***Increasing the width***: We will also try making the model wider by increasing the number of neurons in the hidden layers.\n",
        "\n",
        "We are trying to keep the total number of parameters roughly equivalent for each alteration. This means that if we add more layers (increasing depth), we will have to reduce the number of neurons in each layer (decreasing width) to compensate, and vice versa. The aim is to explore the trade-off between network depth and width.\n",
        "\n",
        "We will evaluate each alteration and compare it to the performance of our original network.\n",
        "\n",
        "### Step 5: Building an Optimized Neural Network\n",
        "Based off of our observations observed in steps 1-4, we will aim to build an optimized fully-connected neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1I9k_du7xDm"
      },
      "source": [
        "# Step 1:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urwvLZA44aYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13df85af-f177-4b01-9dac-980750c6d823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ReLU_Basic\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                196672    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213898 (835.54 KB)\n",
            "Trainable params: 213898 (835.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 15s 9ms/step - loss: 1.8910 - accuracy: 0.3126 - val_loss: 1.7966 - val_accuracy: 0.3565\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7252 - accuracy: 0.3794 - val_loss: 1.7223 - val_accuracy: 0.3894\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.6522 - accuracy: 0.4058 - val_loss: 1.6717 - val_accuracy: 0.3993\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6047 - accuracy: 0.4225 - val_loss: 1.6188 - val_accuracy: 0.4232\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.5669 - accuracy: 0.4361 - val_loss: 1.6086 - val_accuracy: 0.4296\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5394 - accuracy: 0.4466 - val_loss: 1.6427 - val_accuracy: 0.4149\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.5170 - accuracy: 0.4560 - val_loss: 1.5520 - val_accuracy: 0.4411\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4985 - accuracy: 0.4624 - val_loss: 1.5328 - val_accuracy: 0.4563\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4834 - accuracy: 0.4667 - val_loss: 1.5465 - val_accuracy: 0.4444\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4712 - accuracy: 0.4718 - val_loss: 1.5472 - val_accuracy: 0.4488\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5182 - accuracy: 0.4510\n",
            "Test Loss: 1.5182102918624878 Test Accuracy:  0.45100000500679016\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "import keras\n",
        "\n",
        "# Load Data\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "# Define Network\n",
        "\n",
        "model = Sequential(name=\"ReLU_Basic\")\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss, \"Test Accuracy: \", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g16-s8aG74eI"
      },
      "source": [
        "# Step 2:\n",
        "\n",
        "## Observations and Analysis:\n",
        "It looks like ReLU and GeLU perform the best out of any of the other activation functions given the same amount of layers and units in each subsequent layer. Sigmoid being the next best, and TanH the worst.\n",
        "\n",
        "Moving forward, when creating the optimal fully-connected network, we will test between GeLU and ReLU to see if there's a significant difference in performance when limited to 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "boxe8Ce17_CP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e44441e-d863-45c0-9f79-b7fbda0f11d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Sigmoid_Basic\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                196672    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213898 (835.54 KB)\n",
            "Trainable params: 213898 (835.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 2.0159 - accuracy: 0.2486 - val_loss: 1.9001 - val_accuracy: 0.3042\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8639 - accuracy: 0.3211 - val_loss: 1.8568 - val_accuracy: 0.3303\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8108 - accuracy: 0.3432 - val_loss: 1.8156 - val_accuracy: 0.3490\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7779 - accuracy: 0.3515 - val_loss: 1.7846 - val_accuracy: 0.3555\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7473 - accuracy: 0.3674 - val_loss: 1.8026 - val_accuracy: 0.3553\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7270 - accuracy: 0.3720 - val_loss: 1.7385 - val_accuracy: 0.3712\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.7044 - accuracy: 0.3854 - val_loss: 1.7295 - val_accuracy: 0.3759\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6892 - accuracy: 0.3911 - val_loss: 1.7185 - val_accuracy: 0.3823\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6701 - accuracy: 0.3959 - val_loss: 1.7194 - val_accuracy: 0.3862\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6550 - accuracy: 0.4017 - val_loss: 1.7033 - val_accuracy: 0.3828\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6762 - accuracy: 0.3890\n",
            "Model: \"TanH_Basic\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                196672    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213898 (835.54 KB)\n",
            "Trainable params: 213898 (835.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.0300 - accuracy: 0.2406 - val_loss: 1.9592 - val_accuracy: 0.2704\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.9392 - accuracy: 0.2825 - val_loss: 1.9242 - val_accuracy: 0.3005\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.8942 - accuracy: 0.3105 - val_loss: 1.9069 - val_accuracy: 0.3028\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8744 - accuracy: 0.3223 - val_loss: 1.8733 - val_accuracy: 0.3279\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8535 - accuracy: 0.3287 - val_loss: 1.8804 - val_accuracy: 0.3275\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8479 - accuracy: 0.3326 - val_loss: 1.8721 - val_accuracy: 0.3260\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8442 - accuracy: 0.3315 - val_loss: 1.8573 - val_accuracy: 0.3354\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8295 - accuracy: 0.3355 - val_loss: 1.8582 - val_accuracy: 0.3309\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8282 - accuracy: 0.3381 - val_loss: 1.8248 - val_accuracy: 0.3341\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8144 - accuracy: 0.3418 - val_loss: 1.8933 - val_accuracy: 0.3106\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.8809 - accuracy: 0.3125\n",
            "Model: \"GeLU_Basic\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                196672    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213898 (835.54 KB)\n",
            "Trainable params: 213898 (835.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 8s 4ms/step - loss: 1.8692 - accuracy: 0.3178 - val_loss: 1.7314 - val_accuracy: 0.3780\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7059 - accuracy: 0.3855 - val_loss: 1.7177 - val_accuracy: 0.3835\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6359 - accuracy: 0.4113 - val_loss: 1.6558 - val_accuracy: 0.3988\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5974 - accuracy: 0.4279 - val_loss: 1.6192 - val_accuracy: 0.4233\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.5674 - accuracy: 0.4366 - val_loss: 1.6177 - val_accuracy: 0.4186\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5485 - accuracy: 0.4410 - val_loss: 1.5965 - val_accuracy: 0.4314\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.5250 - accuracy: 0.4497 - val_loss: 1.5700 - val_accuracy: 0.4427\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5133 - accuracy: 0.4536 - val_loss: 1.6254 - val_accuracy: 0.4166\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5023 - accuracy: 0.4582 - val_loss: 1.5695 - val_accuracy: 0.4396\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.4896 - accuracy: 0.4650 - val_loss: 1.5670 - val_accuracy: 0.4357\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5403 - accuracy: 0.4449\n"
          ]
        }
      ],
      "source": [
        "# Change activation function (sigmoid, tanh, gelu)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential(name='Sigmoid_Basic')\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=64, activation='sigmoid'))\n",
        "model.add(Dense(units=128, activation='sigmoid'))\n",
        "model.add(Dense(units=64, activation='sigmoid'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential(name='TanH_Basic')\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=64, activation='tanh'))\n",
        "model.add(Dense(units=128, activation='tanh'))\n",
        "model.add(Dense(units=64, activation='tanh'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential(name='GeLU_Basic')\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=64, activation='gelu'))\n",
        "model.add(Dense(units=128, activation='gelu'))\n",
        "model.add(Dense(units=64, activation='gelu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWt1xCuE8fIP"
      },
      "source": [
        " # Step 3:\n",
        "\n",
        "## Observations and Analysis:\n",
        "For the same amount of layers, significantly increasing the number of parameters seems to result in better performance than decreasing the number of parameters.\n",
        "\n",
        "Specifically, the accuracy of the 1024 unit layers resulting in 5256202 total parameters was able to hit 47% accuracy within 10 epochs.\n",
        "\n",
        "On the other hand, the 16 unit layers resulted in 49882 parameters with only 34% accuracy within 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4KULS418tMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290a3580-0d31-4ae2-f6cb-d2010725f383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ReLU_Increased_Parameters\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5256202 (20.05 MB)\n",
            "Trainable params: 5256202 (20.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 1.8999 - accuracy: 0.3059 - val_loss: 1.7457 - val_accuracy: 0.3732\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7310 - accuracy: 0.3731 - val_loss: 1.7110 - val_accuracy: 0.3782\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6569 - accuracy: 0.4005 - val_loss: 1.6875 - val_accuracy: 0.3883\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6103 - accuracy: 0.4175 - val_loss: 1.6172 - val_accuracy: 0.4158\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5613 - accuracy: 0.4377 - val_loss: 1.6288 - val_accuracy: 0.4117\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5218 - accuracy: 0.4491 - val_loss: 1.6033 - val_accuracy: 0.4214\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4856 - accuracy: 0.4623 - val_loss: 1.5582 - val_accuracy: 0.4471\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4556 - accuracy: 0.4718 - val_loss: 1.5213 - val_accuracy: 0.4565\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4270 - accuracy: 0.4831 - val_loss: 1.5520 - val_accuracy: 0.4506\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4013 - accuracy: 0.4912 - val_loss: 1.5876 - val_accuracy: 0.4433\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5608 - accuracy: 0.4516\n",
            "Model: \"ReLU_Decreased_Parameters\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 16)                49168     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49882 (194.85 KB)\n",
            "Trainable params: 49882 (194.85 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.1178 - accuracy: 0.1772 - val_loss: 2.0672 - val_accuracy: 0.1888\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0495 - accuracy: 0.1965 - val_loss: 2.0626 - val_accuracy: 0.1943\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 2.0411 - accuracy: 0.1965 - val_loss: 2.0422 - val_accuracy: 0.1993\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0372 - accuracy: 0.1986 - val_loss: 2.0549 - val_accuracy: 0.1951\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0329 - accuracy: 0.2004 - val_loss: 2.0404 - val_accuracy: 0.2054\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0295 - accuracy: 0.2003 - val_loss: 2.0621 - val_accuracy: 0.1908\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0286 - accuracy: 0.2037 - val_loss: 2.0637 - val_accuracy: 0.1911\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0273 - accuracy: 0.2036 - val_loss: 2.0352 - val_accuracy: 0.2060\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0267 - accuracy: 0.2035 - val_loss: 2.0415 - val_accuracy: 0.2008\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0233 - accuracy: 0.2066 - val_loss: 2.0443 - val_accuracy: 0.1980\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.0277 - accuracy: 0.2034\n"
          ]
        }
      ],
      "source": [
        "# increase number of parameters in the network\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define Network\n",
        "\n",
        "\n",
        "model = Sequential(name=\"ReLU_Increased_Parameters\")\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Reduce number of parameters in the network\n",
        "\n",
        "# Define Network\n",
        "\n",
        "model = Sequential(name=\"ReLU_Decreased_Parameters\")\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiG8r2w867A"
      },
      "source": [
        "# Step 4:\n",
        "\n",
        "## Observations and Analysis:\n",
        "\n",
        " Making the model wider instead of deeper seems to allow the network to perform slightly better for the CIFAR data.\n",
        "\n",
        "Keeping the total amount of parameters for both techniques roughly equivalent, we find that performance of the wider model is slightly better than that of the deeper model.\n",
        "\n",
        "However, this performance boost seems relatively negligable when limited to only 10 epochs and both approaches result in similar validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI7IiwR38_Ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4c38e8-efd5-4acf-b143-a56ed64dfc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ReLU_Increased_Width\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 34)                104482    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 34)                1190      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 34)                1190      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                350       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107212 (418.80 KB)\n",
            "Trainable params: 107212 (418.80 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9525 - accuracy: 0.2814 - val_loss: 1.8757 - val_accuracy: 0.3156\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8131 - accuracy: 0.3443 - val_loss: 1.7929 - val_accuracy: 0.3493\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7694 - accuracy: 0.3598 - val_loss: 1.7809 - val_accuracy: 0.3568\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.7331 - accuracy: 0.3748 - val_loss: 1.7591 - val_accuracy: 0.3658\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7111 - accuracy: 0.3812 - val_loss: 1.7223 - val_accuracy: 0.3846\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6909 - accuracy: 0.3884 - val_loss: 1.7431 - val_accuracy: 0.3719\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6696 - accuracy: 0.3955 - val_loss: 1.7124 - val_accuracy: 0.3819\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6518 - accuracy: 0.4017 - val_loss: 1.6828 - val_accuracy: 0.3975\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6374 - accuracy: 0.4090 - val_loss: 1.7015 - val_accuracy: 0.3869\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6239 - accuracy: 0.4151 - val_loss: 1.6938 - val_accuracy: 0.3966\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6611 - accuracy: 0.4010\n",
            "Model: \"ReLU_Increased_Depth\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 28)                86044     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 28)                812       \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 10)                290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92018 (359.45 KB)\n",
            "Trainable params: 92018 (359.45 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 10s 6ms/step - loss: 2.0104 - accuracy: 0.2341 - val_loss: 1.9409 - val_accuracy: 0.2870\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8571 - accuracy: 0.3196 - val_loss: 1.8383 - val_accuracy: 0.3254\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7997 - accuracy: 0.3421 - val_loss: 1.7870 - val_accuracy: 0.3513\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7664 - accuracy: 0.3569 - val_loss: 1.7778 - val_accuracy: 0.3577\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7415 - accuracy: 0.3655 - val_loss: 1.7575 - val_accuracy: 0.3647\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7289 - accuracy: 0.3710 - val_loss: 1.7585 - val_accuracy: 0.3592\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7175 - accuracy: 0.3738 - val_loss: 1.7275 - val_accuracy: 0.3768\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7028 - accuracy: 0.3807 - val_loss: 1.7264 - val_accuracy: 0.3730\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.6957 - accuracy: 0.3832 - val_loss: 1.7336 - val_accuracy: 0.3739\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6803 - accuracy: 0.3897 - val_loss: 1.7113 - val_accuracy: 0.3806\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6900 - accuracy: 0.3866\n"
          ]
        }
      ],
      "source": [
        "# Increase width, decrease depth\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define Network\n",
        "\n",
        "model = Sequential(name=\"ReLU_Increased_Width\")\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=34, activation='relu'))\n",
        "model.add(Dense(units=34, activation='relu'))\n",
        "model.add(Dense(units=34, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Increase depth, decrease width\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define Network\n",
        "\n",
        "model = Sequential(name=\"ReLU_Increased_Depth\")\n",
        "\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "model.add(Dense(units=28, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99uzMJfH-TBT"
      },
      "source": [
        "# Step 5: Building an Optimized Neural Network\n",
        "\n",
        "\n",
        "Discuss: It seems like for images, having a wider initial neural network results in a better performing model than having a less wide and deep network.\n",
        "\n",
        "While this seemingly goes against what we understand theoretically, the accuracy shows that a 2-3 layered wide network consistently outperforms that of a \"skinnier\" deeper network. Although all approaches for a fully-connected neural network seem to flatten out at around 50% accuracy for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwcJ10tx-Rth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4eb0c6-930c-4c1f-9e58-ba1d7bccdac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Optimized_ReLU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4726282 (18.03 MB)\n",
            "Trainable params: 4726282 (18.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.8814 - accuracy: 0.3143 - val_loss: 1.7780 - val_accuracy: 0.3634\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.6984 - accuracy: 0.3860 - val_loss: 1.6946 - val_accuracy: 0.3909\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6169 - accuracy: 0.4135 - val_loss: 1.5993 - val_accuracy: 0.4277\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.5665 - accuracy: 0.4307 - val_loss: 1.5958 - val_accuracy: 0.4321\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5212 - accuracy: 0.4516 - val_loss: 1.5539 - val_accuracy: 0.4450\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4878 - accuracy: 0.4642 - val_loss: 1.5513 - val_accuracy: 0.4430\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4603 - accuracy: 0.4721 - val_loss: 1.5063 - val_accuracy: 0.4613\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4299 - accuracy: 0.4825 - val_loss: 1.5602 - val_accuracy: 0.4468\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4001 - accuracy: 0.4939 - val_loss: 1.5237 - val_accuracy: 0.4652\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3765 - accuracy: 0.5001 - val_loss: 1.5249 - val_accuracy: 0.4633\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.5164 - accuracy: 0.4668\n"
          ]
        }
      ],
      "source": [
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential(name=\"Optimized_ReLU\")\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Step 5, our Optimized Neural Network\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vHq3Veq6kqPI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMiLBsx2R1bs"
      },
      "source": [
        "# Part 2 CNN\n",
        "\n",
        "Utilizing the Keras Sequential model, we define a Convolutional Neural Network (CNN) model that is adapted to classify images in the CIFAR-10 dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0N5TMYdR1bs"
      },
      "source": [
        "## Observations and Analysis:\n",
        "\n",
        "CNN consistently outperforms the neural network we created in part 1. In addition, our models are deeper rather than wider and reach a near 75% validation accuracy.\n",
        "\n",
        "Between choosing activation functions, out of TanH, Sigmoid, ReLU, and GeLU, we find that from best to worst:\n",
        "\n",
        "GeLU >= ReLU > TanH > Sigmoid\n",
        "\n",
        "One thing we noted was that GeLU had a high training accuracy (reaching nearly 94%) but had a lower/similar validation accuracy as ReLU (around 73-75%)\n",
        "\n",
        "After experimenting around with different kernel sizes, pooling sizes, dropout thresholds and fully-connected layers after flattening, I settled on a kernel size of 3x3 and a pooling size of 2x2 with a dropout of 0.4 after 2 convolutional layers.\n",
        "\n",
        "For the fully-connected layer after flattening, I only added one Dense layer of size 1024, as adding more layers seemingly added more noise and worsened the accuracy.\n",
        "\n",
        "I think one thing that could be added to improve this model would be to potentially add a batch mormalization layer in order to re-center and re-scale the input between each convolutional layer and pooling layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fM1KShylR1bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed4370e-dee2-44f1-8ea1-ed71cc2b4b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 10, 10, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 5, 5, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              3277824   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3548234 (13.54 MB)\n",
            "Trainable params: 3548234 (13.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 17s 12ms/step - loss: 1.4540 - accuracy: 0.4832 - val_loss: 1.0794 - val_accuracy: 0.6149\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 1.0212 - accuracy: 0.6447 - val_loss: 0.8759 - val_accuracy: 0.6949\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8200 - accuracy: 0.7162 - val_loss: 0.8531 - val_accuracy: 0.7129\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.6793 - accuracy: 0.7658 - val_loss: 0.7919 - val_accuracy: 0.7318\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.5634 - accuracy: 0.8027 - val_loss: 0.8079 - val_accuracy: 0.7380\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4706 - accuracy: 0.8371 - val_loss: 0.8868 - val_accuracy: 0.7470\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.4005 - accuracy: 0.8628 - val_loss: 0.8677 - val_accuracy: 0.7436\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3442 - accuracy: 0.8802 - val_loss: 1.1012 - val_accuracy: 0.7335\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3158 - accuracy: 0.8931 - val_loss: 0.9677 - val_accuracy: 0.7373\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2963 - accuracy: 0.9001 - val_loss: 0.9168 - val_accuracy: 0.7518\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.9707 - accuracy: 0.7404\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.datasets import cifar10\n",
        "import keras\n",
        "\n",
        "# Load Data\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential(name='CNN')\n",
        "model.add(Conv2D(64, kernel_size=(3,3), input_shape = (32,32,3), activation='gelu'))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), input_shape= (32,32,3), activation='gelu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), input_shape= (32,32,3), activation='gelu'))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), input_shape= (32,32,3), activation='gelu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024, activation='gelu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# train the model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(x_train_full, y_train_full, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
